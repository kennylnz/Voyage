<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Voyage</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Voyage">
<meta property="og:url" content="https://kennylnz.github.io/index.html">
<meta property="og:site_name" content="Voyage">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Voyage">
  
    <link rel="alternate" href="/Voyage/atom.xml" title="Voyage" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/Voyage/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/Voyage/" id="logo">Voyage</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/Voyage/">Home</a>
        
          <a class="main-nav-link" href="/Voyage/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/Voyage/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://kennylnz.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Docker-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/20/Docker-Notes/" class="article-date">
  <time datetime="2018-10-20T04:43:37.000Z" itemprop="datePublished">2018-10-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/20/Docker-Notes/">Docker Notes</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>So far all the articles of Voyage are docker related, before move to next components, I’d like to note down the issues I met these days, as a close to the Docker chapter.</p>
<h2 id="Mapping-of-Volume-in-windows"><a href="#Mapping-of-Volume-in-windows" class="headerlink" title="Mapping of Volume in windows."></a>Mapping of Volume in windows.</h2><p>It turns out when you run docker in windows, and your container is Linux, you will encounter access issue when container r/w on the mapped volume(seems only apply to NTFS). Solution could be:<br>1 Add a new partition in your windows in non-NTFS format, and map from there.<br>2 Run Docker in linux image.<br>3 Run Windows container.</p>
<h2 id="Files-could-not-be-removed"><a href="#Files-could-not-be-removed" class="headerlink" title="Files could not be removed."></a>Files could not be removed.</h2><p>It seems due to Docker’s image layer mechanism, you can’t remove files created in lower layer in higher layers during image build. Although everything looks fine during image build, the file will come back when you start container from the image. Solution could be:<br>1 if you have temp file during your image build, put all the step in one single line, for example<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line"></span><br><span class="line">COPY install.zip /usr/<span class="built_in">local</span>/install</span><br><span class="line">RUN unzip install.zip \</span><br><span class="line">  &amp;&amp; install/install.sh\</span><br><span class="line">  &amp;&amp; rm -Rf install</span><br></pre></td></tr></table></figure></p>
<p>The unzipped files will be used to install, and last step of the run will remove the unzipped files.  And you might aware that the install.zip you will not able to remove. This actually becomes a principle when you orchestrate your docker file, each step in docker file should be an atomic operation that add extra valuable layer to the image(technically you could have your docker file perform one command per step, but that will likely make your image a mess).</p>
<h2 id="Container-Disk-full"><a href="#Container-Disk-full" class="headerlink" title="Container Disk full"></a>Container Disk full</h2><p>I installed docker toolkit in a win7, which actually runs a Linux virtual machine, and runs docker container within that machine. it turns out the default VM machine created by toolkit only has 20GB disk space. When you have big images like oracle db, or you built many images, you will run out of disk space for the docker machine.  As the disk space within the container actually rely one this disk as well, your container will be impacted as well. You have 2 options to solve this problem.<br>1 Manually create your docker machine with parameter –virtualbox-disk-size followed by a size in mb.  you will need rebuild all your images if you still have your docker file.<br>2 Resize the default docker machine disk by first resize the VM disk file, and then expand the mount point by GParted(try Google for detailed steps).</p>
<p>It looks like option 2 might be more helpful.</p>
<h2 id="Docker-image-and-docker-container"><a href="#Docker-image-and-docker-container" class="headerlink" title="Docker image and docker container."></a>Docker image and docker container.</h2><p>We know that image is static file, while container is a running machine. Sometimes it might be confusing when you plan to build your docker image that requires a running software instance. Imagine you have a oracle image have oracle product installed. and what you need to do are:<br>1 create a oracle database.<br>2 run some DDL to initialize your project tables.<br>but to perform step 2 you need a running oracle instance, which means you might need run your container to have a running instance. You can then run your DDL, but that is not part of your  image build based on Dockerfile. You could commit your container as a new image. but then your image build process is a little bit complex(or looks not so well organized). </p>
<p>The option that I figure out is that in your Dockerfile you could start your oracle instance and then run your DDL (in one step of dockerfile). You might say that ultimately it’s the same, you start a instance and run DDL, then save it as new image, which is actually right. the only difference is I see is you could sort out your image build in single docker file with this approach.  Otherwise you will need a shell/bat script that 1 start docker container, 2 run DDL,  3 commit container as image, while you might still need Dockerfile to perform some other steps.</p>
<h2 id="NAT-setting-when-run-docker-in-win7"><a href="#NAT-setting-when-run-docker-in-win7" class="headerlink" title="NAT setting when run docker in win7."></a>NAT setting when run docker in win7.</h2><p>I started play with docker in my laptop, which is a win10 machine. The docker process runs directly in win10. the -p command line parameter works perfectly. But when I shipped my Dockerfile to my win7 workstation, which runs docker within a VM created by docker-toolkit. The -p parameter for port forwarding did not work. The reason is that as the docker process was ran within the Linux VM created by docker-toolkit, the port forwarding actually means forward the package reached the VM to the container. What you still need to do is to enable the port forwarding in the virtual-box VM settings (I see the VM’s NIC was set as NAT by default, did not try to change to other), so that package reached your host get forwarded to your VM machine. The setting is pretty straight forward in the VirtualBox settings, and effect right after the change applied.</p>
<h2 id="Might-need-add-some-waits-between-steps"><a href="#Might-need-add-some-waits-between-steps" class="headerlink" title="Might need add some waits between steps."></a>Might need add some waits between steps.</h2><p>Due to the idea of starting oracle(or some middle-ware) and apply DDL ( or deploy a ear) in the Dockerfile steps. Sometimes when the script started instance, the instance is actually not fully ready for use, your followed step of deploying might fail(So far this happened to middle-ware a lot, did not happen to oracle during my tests). So some waits after middle-ware instances started might be needed. </p>
<h2 id="Unresolved-issues"><a href="#Unresolved-issues" class="headerlink" title="Unresolved issues."></a>Unresolved issues.</h2><p>1 Oracle image build steps is very slow, it seems caused by the poor I/O performance.<br>2 When I tuning the Dockerfile, I need run build a lot of times, this caused a lot of untagged images. Still haven’t figured out how to avoid it.  same happens to containers as well.<br>3 Haven’t actually tried volume mapping, was trying to avoid using it, turns out so far it’s not needed.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/20/Docker-Notes/" data-id="cjnh1d3jj00009wvo6hve2dpr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Docker-Summarize" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/19/Docker-Summarize/" class="article-date">
  <time datetime="2018-10-19T09:11:49.000Z" itemprop="datePublished">2018-10-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/19/Docker-Summarize/">Docker Summarize</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Docker Summarize</p>
<p>Spent some time this week play with docker, the overall experience really amazed me by the simplicity to use, and reliability so far. Let me make a summarize on my understanding.</p>
<h2 id="What-problem-it-solves"><a href="#What-problem-it-solves" class="headerlink" title="What problem it solves."></a>What problem it solves.</h2><p>There are many articles on the Internet explains what’s docker, many of them are statement like, which might be obscure to understand. I would like to simplify it as:<br>Docker helps you to build up your environment, so that you just need build it once, and able ship it to anyway, or scale up/down with least effort.</p>
<p>Imagine you started a java web project, after coding a couple of days happily, you need to run you code. So you need do following<br>1 download a jdk, and install on your machine.<br>2 download a tomcat, and install it.<br>3 build your project as war file and deploy it to tomcat<br>4 you might need install a mysql as well.<br>5 you need create a database in mysql and run your projects ddl.</p>
<p>You might say that you should already have jdk installed before you start coding, fine, let’s skip that. After you ran , debug , fixed your code. finally it’s ready for tester’s test.<br>You or someone in the team need repeat step 1-5 again, probably on a linux environment, which means he might run into some issues during installation, he Googled it and solved it.<br>After testing ready to hand-over to operation team to go pre-prod (or something similar), the operation team, repeated the step 1-5 again, and might still run into some issues, as the document was poorly maintained.<br>And the same happened for production.<br>And the same*x happened as the application was great success which need scale up by repeating 1-5 on more servers.</p>
<p>And some day, when your V1.5 release deployed to production, the application crashed, due to you have adjusted one parameter of tomcat during your development, but the adjustment was not applied in production.<br>And in another day, you are working on your V2.0, some serve defect from production need be fixed, but you realized you have changed db design that you can’t test it with current environment, thus you decided to get a new machine and repeat 1-5.<br>The situation continued when V2.0 delivered to Pre-Prod, and you start working on V3.0,  that you need an environment for V2.0, one for V3.0, and you still have to keep one for V1.5 as well.</p>
<p>You could probably see that in this case there are following challenges.<br>1 environment setup activities been repeated many times.<br>2 environment settings are not identical<br>3 you need dedicated environment for each branch that delivered.</p>
<p>Docker is good at solving these challenges. </p>
<h2 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works."></a>How it works.</h2><p>Google gives you best technical answer for this question. I will just try to describe it in language that easier to understand.<br>An environment usually consists of : OS/Middleware/DB/Application. Docker helps you to pack up these components, so you can ship to other places to run it. This still sounds not much difference to Virtual Machine. Yes, it’s similar. But you might know that any VM image can easily goes up to 10 GB, shipping it around does not sound like a good idea. With docker you don’t need to ship the VM image, you can just ship the steps that setup the environment. Well, that sounds like scripting. Yes, very similar. but docker does it slightly different with it’s “layers” of images.<br>At it’s base layer, it’s a linux OS image( could be windows as well), you can install your components in the OS image, and publish it as a new image. Then others can pull your image to run the environment elsewhere. which still looks like shipping vm image, with some difference. because the base layer it’s a Linux OS, you just need pull it once, it could be used as base for man other images. which means it reduced the amount of data been shipped.<br>Another way of doing it is, when you install your components, you can install via Dockerfile steps. Once it’s done, you can just share your Dockerfile, so anyone can build up same environment by bulid based on your docker file.</p>
<p>It’s like the dockerfile can de-dimension a environment into a single text file.</p>
<h2 id="How-to-use-it"><a href="#How-to-use-it" class="headerlink" title="How to use it."></a>How to use it.</h2><p>I’m leaving Google to give the technical answer, as you could fine many 15 minutes tutorial to tell how should it be used. I will focus on how to use it in real life projects. In traditional way, you install components step by step, you might create a document for it. or you might create some script for it. Both are helpful. In docker, you need to do it by coding your dockerfile step by step. Once you have finished your Dockerfile, the effort required to replicate the environment becomes very low. And you should always have consist environment.</p>
<h2 id="What’s-the-best-practice"><a href="#What’s-the-best-practice" class="headerlink" title="What’s the best practice."></a>What’s the best practice.</h2><p>As we know docker is good at shipping and scaling your environment. It can help companies to scale the application to hundreds nodes. But not everyone works in Internet companies that build applications support millions users.  Does that mean docker is not needed for projects does not need large scale clusters? The answer is yes and no, Yes， because if you don’t have  needs of scale up, then docker does not add value to you in that aspect. But projects can still benefit from applying Docker for shipping environment , automation as well as “branching” your environment</p>
<p>In my understanding, following principles should help when applying Docker in project.<br>1 Use docker file to build up environment. You could start your container, and install components there, and then commit your container, but this means you will need ship your image rather than much smaller docker files.<br>2 Organize your components as stacks, and plan your docker files according to the stack. the factor for defining the order in stack would be:<br>  a, dependency, components been dependent on show stay at lower layer.<br>  b, frequency of change, frequently changed components should be placed at upper layer. it wil save time when rebuilding the image.<br>  c, layers should be reasonably grouped. for example, you might have a environment consist of OS/Oracle product/Oracle Database/project DDL/project initial data.  it might be good to group them to [os/oracle product, oracle db, project ddl/initial data], each of the group has a image, and it’s built from previous group.</p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>Docker image for Oracle product : sath89/oracle-12c,  you can pull it from docker hub, it contains oracle product, and an entry script that can create oracle db and start instance.<br>Docker file for DB layer image:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">FROM sath89/oracle-12c:latest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">COPY *.sh /</span><br><span class="line">RUN /createInstance.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set entrypoint to run management script</span></span><br><span class="line">ENTRYPOINT [<span class="string">"/entrypoint.sh"</span>]</span><br><span class="line">`</span><br></pre></td></tr></table></figure></p>
<p>The file copy the createInstance.sh script into the base image and run it to create db. Once completed, the updated image is saved as a new image. </p>
<p>Dockerfile for application level artifacts:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM oracle_instance:0.1</span><br><span class="line">ENV IMPORT_FROM_VOLUME=<span class="literal">true</span></span><br><span class="line">COPY c360 /docker-entrypoint-initdb.d/</span><br><span class="line">RUN /startInstance.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set entrypoint to run management script</span></span><br><span class="line">ENTRYPOINT [<span class="string">"/entrypoint.sh"</span>]</span><br></pre></td></tr></table></figure></p>
<p>This docker file start db instance and run the ddl at for application. ddl should be placed in /docker-entrypoint-initdb.d/.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/19/Docker-Summarize/" data-id="cjnh1d3k000029wvowuquqa6o" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Access-DynamoDB-from-Browser" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/14/Access-DynamoDB-from-Browser/" class="article-date">
  <time datetime="2018-10-14T08:29:43.000Z" itemprop="datePublished">2018-10-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/14/Access-DynamoDB-from-Browser/">Access DynamoDB from Browser</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Enough headache for environment issues? It’s time to move to cloud. Let’s talk about DynamoDB today.<br>We will first spend sometime to see how it works, although Amazon tutorial addresses it pretty well, I will try to cover it in one article. And then I will spend some time to share my understanding about it.</p>
<h2 id="DynamoDB"><a href="#DynamoDB" class="headerlink" title="DynamoDB"></a>DynamoDB</h2><p>DynamoDB is Amazon’s cloud based No-SQL db. Cloud makes it available in couple of clicks, and there is SDK for most popular languages. We will use browser side javascript to access the Dynamo DB in AWS. Here is the plan:<br>1 Ensure you have your AWS account ready.<br>2 Create User from your AWS IAM console,and keep the keys in a safe place.<br>3 Coding</p>
<p>I’ll skip step 1.</p>
<h2 id="AWS-keys"><a href="#AWS-keys" class="headerlink" title="AWS keys"></a>AWS keys</h2><p>I want to avoid including screen-shots in this article, as the User Interface of AWS console will change for sure. I will just include high level steps.<br>1 Search for “IAM” from the home of your AWS console.<br>2 Go to Users, and create user by following the wizard, you might need create a group and grant some access to the group. just select according to your common sense.<br>3 finally you will see a page that provides you the Access Key and Secured Secret access key, please keep the value in a safe place ( you will not able to see the Secret access key after you leave the page)</p>
<h2 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h2><p>Amazon provides very <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GettingStarted.JavaScript.html" target="_blank" rel="noopener">nice tutorial</a>, I will use the same tutorial, while adding some explanations.</p>
<p>As we plan to access DynamoDB from browser directly, there will be some issue with the “Cross Domain”, when accessing resources by Javascript from another domain. Amazon tutorial provided the solution.</p>
<h3 id="Create-table"><a href="#Create-table" class="headerlink" title="Create table"></a>Create table</h3><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://sdk.amazonaws.com/js/aws-sdk-2.7.16.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">AWS.config.update(&#123;</span></span><br><span class="line"><span class="undefined">  region: "ap-southeast-2",</span></span><br><span class="line"><span class="undefined">  endpoint: 'https://dynamodb.ap-southeast-2.amazonaws.com',</span></span><br><span class="line"><span class="undefined">  // accessKeyId default can be used while using the downloadable version of DynamoDB. </span></span><br><span class="line"><span class="undefined">  // For security reasons, do not store AWS Credentials in your files. Use Amazon Cognito instead.</span></span><br><span class="line"><span class="undefined">  accessKeyId: "xxxx",</span></span><br><span class="line"><span class="undefined">  // secretAccessKey default can be used while using the downloadable version of DynamoDB. </span></span><br><span class="line"><span class="undefined">  // For security reasons, do not store AWS Credentials in your files. Use Amazon Cognito instead.</span></span><br><span class="line"><span class="undefined">  secretAccessKey: "yyyy"</span></span><br><span class="line"><span class="undefined">&#125;);</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">var dynamodb = new AWS.DynamoDB();</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">function createMovies() &#123;</span></span><br><span class="line"><span class="undefined">    var params = &#123;</span></span><br><span class="line"><span class="undefined">        TableName : "Movies",</span></span><br><span class="line"><span class="undefined">        KeySchema: [</span></span><br><span class="line"><span class="undefined">            &#123; AttributeName: "year", KeyType: "HASH"&#125;,</span></span><br><span class="line"><span class="undefined">            &#123; AttributeName: "title", KeyType: "RANGE" &#125;</span></span><br><span class="line"><span class="undefined">        ],</span></span><br><span class="line"><span class="undefined">        AttributeDefinitions: [</span></span><br><span class="line"><span class="undefined">            &#123; AttributeName: "year", AttributeType: "N" &#125;,</span></span><br><span class="line"><span class="undefined">            &#123; AttributeName: "title", AttributeType: "S" &#125;</span></span><br><span class="line"><span class="undefined">        ],</span></span><br><span class="line"><span class="undefined">        ProvisionedThroughput: &#123;</span></span><br><span class="line"><span class="undefined">            ReadCapacityUnits: 5,</span></span><br><span class="line"><span class="undefined">            WriteCapacityUnits: 5</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined">    &#125;;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    dynamodb.createTable(params, function(err, data) &#123;</span></span><br><span class="line"><span class="undefined">        if (err) &#123;</span></span><br><span class="line"><span class="undefined">            document.getElementById('textarea').innerHTML = "Unable to create table: " + "\n" + JSON.stringify(err, undefined, 2);</span></span><br><span class="line"><span class="undefined">        &#125; else &#123;</span></span><br><span class="line"><span class="undefined">            document.getElementById('textarea').innerHTML = "Created table: " + "\n" + JSON.stringify(data, undefined, 2);</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined">    &#125;);</span></span><br><span class="line"><span class="undefined">&#125;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">id</span>=<span class="string">"createTableButton"</span> <span class="attr">type</span>=<span class="string">"button"</span> <span class="attr">value</span>=<span class="string">"Create Table"</span> <span class="attr">onclick</span>=<span class="string">"createMovies();"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">textarea</span> <span class="attr">readonly</span> <span class="attr">id</span>= <span class="string">"textarea"</span> <span class="attr">style</span>=<span class="string">"width:400px; height:800px"</span>&gt;</span><span class="tag">&lt;/<span class="name">textarea</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Couple of points to explain. The AWS.config.update part set up connection info to the Dynamo DB. Region and endpoint can be found from <a href="https://docs.aws.amazon.com/general/latest/gr/rande.html#ddb_region" target="_blank" rel="noopener">Amazon DynamoDB Regions</a>.<br>accessKeyId and secretAccessKey is the one you got from the “AWS keys” section. This application is for learning purpose, so we just hard coded the key. You can’t use it for production application as Javascript runs in browser, you will leak your keys, and there is chance that you might get huge bills from AWS if someone use your key to do something good. The suggested solution by Amazon is “Cognito”.</p>
<p>If you open the HTML and click the button, you will get your table created. Simple as that!<br>I will skip the rest of steps in the Amazon tutorial,as it pretty straight forward.</p>
<h2 id="My-feeling"><a href="#My-feeling" class="headerlink" title="My feeling."></a>My feeling.</h2><p>This cloud experience explained why Amazon stock price soars. As IBMer, I see everything from AWS familiar, but everything is slightly different. The No-SQL DB from data structure wise is not much new to the “hierarchical database” IMS from IBM, which was running since 1970s, and it still runs many of the most important systems in the world, Banks, Government, Stock Exchange you name it. The IAM, which IBM have solution with exact same name based on Tivoli Directory Server. Are all these AWS services new wheels? No, there are definitely something new with these AWS services – openness and easiness. I can’t imaging anyone can finish a hello word application based on IBM traditional products in 15 minutes. That’s the time for downloading the tool. Sorry, you need half story point for that? OK, you got your half story point. Young might 1 story point for installation, 2 story points to read document(which you don’t know where you can find it yet, if you can’t you might try Google it.) and 1 for coding, 1 for testing. AH you’ve got your plan for the week, and slightly overloaded! But in AWS case, it’s cloud based, you don’t need install, you don’t even need any configuration ( it scales automatically), It provide SDK for most popular languages(Java, Javascript, Python, you name it), It has well prepared tutorials to demonstrate the key features. </p>
<p>Another major difference I see from AWS services is that it focus on providing most fundamental feature per service, rather than include everything in one solution or product. Which actually simplified the service it provides and the usage of it. It does not have complex configuration or tuning parameters that you need to know. Well, it might be still complex at their back-end, but from user perspective it’s simple. We could say in the IBM-era, by providing IBM complex product and IBM specialist together, IBM still provide customer great experience with simplicity, as long as customer pay the bills. Then what is the core difference? I would say in IBM-era, IT were treated as high-tech, it’s something new, that requires specialist. But in Cloud-era, IT is mandatory for any organization, and it’s a utility that need be simple enough for non-specialist. Imagine electricity, you don’t need to have a generator at home, or hire someone to change light bulb for you. Also financially Cloud bases services are charged by usage, which means the initial investment could be very limited, so you can avoid the risk of huge investment on some wrong decision.</p>
<p>Does this mean the traditional IBM businesses will die, you don’t need a specialist anymore? I don’t think so, many of the cloud based services does not have all the features of traditional product, because of it’s nature of simplicity(you can argue that the features can be improved, but that will make it like big fat product again), so there will always be needs for specialist, but the criteria become higher. In the past, if someone knows how to install MQ, and setup a QMGR with some queues, or knows how to read/put messages from/into MQ, then you might be considered as a MQ specialist. But now,  knowing how to create a queue and read/put message from/into queues from AWS, is just 15 minutes job, that’s not something qualify you as specialist. You need to be someone knows how to utilize the messaging mechanism to build up your application, design your messaging infrastructure so it’s HAHP, secure your message, etc. to be a messaging specialist.</p>
<p>Company like IBM might lost some of it’s business, but she is working one exploring new business. Just like the selling of her PC and X86 server business. The logic IBM makes money is to find an area that no-body else knows but everybody wants, and ask for a staggering price. It has not been changed yet, and same logic applied by many of successful companies in the world, like apple. But still there are companies like Costco, Amazon, MI pursuing low GP form their operations, which are also great companies. Which style will last longer? I don’t know.</p>
<h2 id="Important-Notes"><a href="#Important-Notes" class="headerlink" title="Important Notes"></a>Important Notes</h2><p>After finishing this article, I thought about trying to run the application as part of my github pages site. So I pushed the tutorial code with my access key hard-coded to GIT. I found it did not work as expected, when I login to my AWS console, I found the user I created was delete, and a new user and group was created. My feeling is there might be some one hooked git hub pages and added some behavior to access your AWS account based on the hard coded keys. So, PLEASE ONLY RUN YOUR EXAMPLE WITH ACCESS KEY HARD CODED IN YOUR LOCAL MACHINE.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/14/Access-DynamoDB-from-Browser/" data-id="cjnh1d3jv00019wvoz8nhut8j" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Dockerize-Spark-2-3-2-Hadoop-2-7-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/13/Dockerize-Spark-2-3-2-Hadoop-2-7-1/" class="article-date">
  <time datetime="2018-10-13T01:25:32.000Z" itemprop="datePublished">2018-10-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/13/Dockerize-Spark-2-3-2-Hadoop-2-7-1/">Dockerize Spark 2.3.2 + Hadoop 2.7.1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Today let’s talk about how to dockerize Spark, a Lightning-fast unified analytics engine.<br>If you search official image hub for Spark, you will find following<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NAME                                   DESCRIPTION                                     STARS               OFFICIAL            AUTOMATED</span><br><span class="line">sequenceiq/spark                       An easy way to try Spark                        415                                     [OK]</span><br><span class="line">jupyter/all-spark-notebook             Jupyter Notebook Python, Scala, R, Spark, Me…   200</span><br><span class="line">gettyimages/spark                      A debian:jessie based Spark container           103                                     [OK]</span><br><span class="line">mesosphere/spark                       DCOS Spark                                      86</span><br></pre></td></tr></table></figure></p>
<p>Let’s just start with most popular ones, sequenceiq/spark. But you will find from their <a href="https://hub.docker.com/r/sequenceiq/spark/" target="_blank" rel="noopener">website</a>, is for spark 1.6. That’s too old.<br>Let’s see whether we can build image for latest spark based on some of their work. The plan is get sequenceiq/spark’s docker file and make updates to their articfacts to install latest spark</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/sequenceiq/docker-spark</span><br></pre></td></tr></table></figure>
<p>In the Dockerfile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">FROM sequenceiq/hadoop-docker:2.6.0</span><br><span class="line">MAINTAINER SequenceIQ</span><br><span class="line"></span><br><span class="line">#support for Hadoop 2.6.0</span><br><span class="line">RUN curl -s http://d3kbcqa49mib13.cloudfront.net/spark-1.6.1-bin-hadoop2.6.tgz | tar -xz -C /usr/local/</span><br><span class="line">RUN cd /usr/local &amp;&amp; ln -s spark-1.6.1-bin-hadoop2.6 spark</span><br><span class="line">ENV SPARK_HOME /usr/local/spark</span><br><span class="line">RUN mkdir $SPARK_HOME/yarn-remote-client</span><br><span class="line">ADD yarn-remote-client $SPARK_HOME/yarn-remote-client</span><br><span class="line"></span><br><span class="line">RUN $BOOTSTRAP &amp;&amp; $HADOOP_PREFIX/bin/hadoop dfsadmin -safemode leave &amp;&amp; $HADOOP_PREFIX/bin/hdfs dfs -put $SPARK_HOME-1.6.1-bin-hadoop2.6/lib /spark</span><br><span class="line"></span><br><span class="line">ENV YARN_CONF_DIR $HADOOP_PREFIX/etc/hadoop</span><br><span class="line">ENV PATH $PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin</span><br><span class="line"># update boot script</span><br><span class="line">COPY bootstrap.sh /etc/bootstrap.sh</span><br><span class="line">RUN chown root.root /etc/bootstrap.sh</span><br><span class="line">RUN chmod 700 /etc/bootstrap.sh</span><br><span class="line"></span><br><span class="line">#install R</span><br><span class="line">RUN rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm</span><br><span class="line">RUN yum -y install R</span><br><span class="line"></span><br><span class="line">ENTRYPOINT [&quot;/etc/bootstrap.sh&quot;]</span><br></pre></td></tr></table></figure></p>
<p>Go thru the file quickly, It’s based on hadoop 2.6 image, also from sequenceiq. It downloads the spark 1.6.1, and put spark files to hadoop server. so here is out plan of updating<br>1 use latest hadoop image from <a href="https://github.com/sequenceiq/hadoop-docker" target="_blank" rel="noopener">sequenceiq</a>, which is 2.7.1<br>2 download latest spark on hadoop 2.7.1 which is <a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">2.3.2on hadoop 2.7.1 </a>.<br>3 update bootstrap(from the sequenceiq git project) file for starting hadoop/spark.<br>4 spark 2.3.2 requires jdk1.8, but hadoop image we got is using jdk 1.7,  luckily, when installing the R, jdk1.8 was installed. so we need switch the link of java to point to jdk1.8<br> which is installed at /usr/lib/jvm/jre-1.8.0-openjdk.x86_64/ (the hadoop-env in sequenceiq’s image using /usr/java/default for JAVA_HOME )<br>5 it turns out the sequenceiq image will run into memory issue, I have to tune the yarn memory setting couple of times.</p>
<p>yarn-site.xml under the yarn-remote-client, add following properties. there is some redundant between them you can google it for more percise setting according to your environment.<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether virtual memory limits will be enforced for containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether physical memory limits will be enforced for containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Whether physical memory limits will be enforced for containers.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>New Dockerfile, adjusted the order of steps to put slow steps in the front(downloading, installing) so it wil be faster if you rebuild image when Dockerfile adjusted.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#support for Hadoop 2.7.1</span></span><br><span class="line">FROM sequenceiq/hadoop-docker:2.7.1</span><br><span class="line">MAINTAINER Voyage</span><br><span class="line"></span><br><span class="line">RUN curl -s https://archive.apache.org/dist/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz | tar -xz -C /usr/<span class="built_in">local</span>/</span><br><span class="line">RUN <span class="built_in">cd</span> /usr/<span class="built_in">local</span> &amp;&amp; ln -s spark-2.3.2-bin-hadoop2.7 spark</span><br><span class="line">ENV SPARK_HOME /usr/<span class="built_in">local</span>/spark</span><br><span class="line">RUN mkdir <span class="variable">$SPARK_HOME</span>/yarn-remote-client</span><br><span class="line">ADD yarn-remote-client <span class="variable">$SPARK_HOME</span>/yarn-remote-client</span><br><span class="line"></span><br><span class="line"><span class="comment">#install R</span></span><br><span class="line">RUN rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm</span><br><span class="line">RUN yum -y install R</span><br><span class="line"></span><br><span class="line"><span class="comment">#use jdk 1.8</span></span><br><span class="line">RUN rm /usr/java/default</span><br><span class="line">RUN ln -s /usr/lib/jvm/jre-1.8.0-openjdk.x86_64/ /usr/java/default</span><br><span class="line"></span><br><span class="line"><span class="comment">#put spark lib jars into hadoop</span></span><br><span class="line">RUN <span class="variable">$BOOTSTRAP</span> &amp;&amp; <span class="variable">$HADOOP_PREFIX</span>/bin/hadoop dfsadmin -safemode leave &amp;&amp; <span class="variable">$HADOOP_PREFIX</span>/bin/hdfs dfs -put <span class="variable">$SPARK_HOME</span>/jars /spark</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ENV YARN_CONF_DIR <span class="variable">$HADOOP_PREFIX</span>/etc/hadoop</span><br><span class="line">ENV PATH <span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$HADOOP_PREFIX</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># update boot script</span></span><br><span class="line">COPY bootstrap.sh /etc/bootstrap.sh</span><br><span class="line">RUN chown root.root /etc/bootstrap.sh</span><br><span class="line">RUN chmod 700 /etc/bootstrap.sh </span><br><span class="line"></span><br><span class="line"><span class="comment"># update yarn config</span></span><br><span class="line">RUN mv <span class="variable">$HADOOP_PREFIX</span>/etc/hadoop/yarn-site.xml <span class="variable">$HADOOP_PREFIX</span>/etc/hadoop/yarn-site.xml.bk</span><br><span class="line">RUN cp <span class="variable">$SPARK_HOME</span>/yarn-remote-client/yarn-site.xml <span class="variable">$HADOOP_PREFIX</span>/etc/hadoop/yarn-site.xml</span><br><span class="line"></span><br><span class="line">ENTRYPOINT [<span class="string">"/etc/bootstrap.sh"</span>]</span><br></pre></td></tr></table></figure></p>
<p>minor update to the bootstrap.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">: <span class="variable">$&#123;HADOOP_PREFIX:=/usr/local/hadoop&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$HADOOP_PREFIX</span>/etc/hadoop/hadoop-env.sh</span><br><span class="line"></span><br><span class="line">rm /tmp/*.pid</span><br><span class="line"></span><br><span class="line"><span class="comment"># installing libraries if any - (resource urls added comma separated to the ACP system variable)</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$HADOOP_PREFIX</span>/share/hadoop/common ; <span class="keyword">for</span> cp <span class="keyword">in</span> <span class="variable">$&#123;ACP//,/ &#125;</span>; <span class="keyword">do</span>  <span class="built_in">echo</span> == <span class="variable">$cp</span>; curl -LO <span class="variable">$cp</span> ; <span class="keyword">done</span>; <span class="built_in">cd</span> -</span><br><span class="line"></span><br><span class="line"><span class="comment"># altering the core-site configuration</span></span><br><span class="line">sed s/HOSTNAME/<span class="variable">$HOSTNAME</span>/ /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/core-site.xml.template &gt; /usr/<span class="built_in">local</span>/hadoop/etc/hadoop/core-site.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># setting spark defaults</span></span><br><span class="line"><span class="built_in">echo</span> spark.yarn.jars hdfs:///spark/* &gt; <span class="variable">$SPARK_HOME</span>/conf/spark-defaults.conf</span><br><span class="line">cp <span class="variable">$SPARK_HOME</span>/conf/metrics.properties.template <span class="variable">$SPARK_HOME</span>/conf/metrics.properties</span><br><span class="line"></span><br><span class="line">service sshd start</span><br><span class="line"><span class="variable">$HADOOP_PREFIX</span>/sbin/start-dfs.sh</span><br><span class="line"><span class="variable">$HADOOP_PREFIX</span>/sbin/start-yarn.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CMD=<span class="variable">$&#123;1:-"exit 0"&#125;</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"<span class="variable">$CMD</span>"</span> == <span class="string">"-d"</span> ]];</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">	service sshd stop</span><br><span class="line">	/usr/sbin/sshd -D -d</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	/bin/bash -c <span class="string">"$*"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>bulid the image， tag it with voyage/spark, version 2.3.2<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build --rm -t voyage/spark:2.3.2 .</span><br></pre></td></tr></table></figure></p>
<p>the first time might be slow as you need pull the hadoop image.</p>
<p>run a container<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it -p 8088:8088 -p 8042:8042 -p 4040:4040 -h sandbox voyage/spark:2.3.2 bash</span><br></pre></td></tr></table></figure></p>
<p>Run the yarn client to verify, within the container. please ensure you have enough memory for your container(container os, hadoop &amp; spark)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash-4.1<span class="comment"># spark-shell --master yarn --deploy-mode client --driver-memory 1g --executor-memory 1g --executor-cores 1</span></span><br></pre></td></tr></table></figure></p>
<p>you should be able to see<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">....</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">'_/</span></span><br><span class="line"><span class="string">   /___/ .__/\_,_/_/ /_/\_\   version 2.3.2</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_181)</span></span><br><span class="line"><span class="string">Type in expressions to have them evaluated.</span></span><br><span class="line"><span class="string">Type :help for more information.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">scala&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>now you can run some scala script</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; sc.parallelize(<span class="number">1</span> to <span class="number">1000</span>).count()</span><br><span class="line">res0: <span class="type">Long</span> = <span class="number">1000</span>                                                      </span><br><span class="line">scala&gt;</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/13/Dockerize-Spark-2-3-2-Hadoop-2-7-1/" data-id="cjnh1d3kc00059wvo7ety8i8o" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Dockerize-Mongo-and-Nodejs" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/11/Dockerize-Mongo-and-Nodejs/" class="article-date">
  <time datetime="2018-10-11T09:56:10.000Z" itemprop="datePublished">2018-10-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/11/Dockerize-Mongo-and-Nodejs/">Dockerize Mongo and Nodejs</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to the first technical article of the Voyage programme. Today, let’s talk about Node.js and Mongo DB. </p>
<h2 id="Node-js"><a href="#Node-js" class="headerlink" title="Node.js"></a>Node.js</h2><p>Node.js provide javascript the capability to be a backend language, and a very good one. Unlike the java language’s dependency and package management mechanism evolved from ant, maven, graddle, Node.js have the npm as package managemer from day 1, and it’s very handy and easy to use. Which makes node.js very easy to start.</p>
<h3 id="Guides"><a href="#Guides" class="headerlink" title="Guides"></a>Guides</h3><p>Best documentation so far I found is the <a href="https://nodejs.org/en/docs/" target="_blank" rel="noopener">Offical documentation</a>, which has very nice start up <a href="https://nodejs.org/en/docs/guides/" target="_blank" rel="noopener">Guides</a>.<br>Although I got most of the knowledge from the website above, I still want to write some words about my understanding, it can also served as appetizer before you dive in to the official documentations.</p>
<h4 id="Development-tools"><a href="#Development-tools" class="headerlink" title="Development tools."></a>Development tools.</h4><p>In my early days of java programming, javascript was embed in JSP to do some UI side logic, like validation, alerts etc. In those days javascript was not considered a real programming language. You don’t have a dedicated IDE ( although you don’t really need one), there is no way to debug ( I used to alert step by step to debug). But these days, javascript has been well developed that it’s almost de facto standard language for front end, node.js makes it a very handy backend language. You got debug tool that naturally ready for remote debug. you can even profiling the node.js process for performance tuning, and containerizing. Because it’s new, it stands on the shoulder of old ones, it has all the goodies built in naturally, while avoiding designs that proved by the old ones to be bad.</p>
<h4 id="Call-backs"><a href="#Call-backs" class="headerlink" title="Call backs."></a>Call backs.</h4><p>Because javascipt is a scripting language, it allows functions to be passed as parameter. Which enables call-back mechanism.  Call-back is one of the ways to achieve IoC, which used to decouple between different models. Java rely on Spring for the same purpose.<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">app.use(<span class="function"><span class="keyword">function</span>(<span class="params">err, req, res, next</span>) </span>&#123;</span><br><span class="line">    res.status(err.status || <span class="number">500</span>);</span><br><span class="line">    res.render(<span class="string">'error'</span>, &#123;</span><br><span class="line">        message: err.message,</span><br><span class="line">        error: err</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>From coding perspective, the call-back style is the biggest difference I feel comparing to Java. it’s not just about how you type the code, it actually requires different way of thinking, in Java(and many other language) you write code line by line, and in your mind it runs from top to bottom, like flow.  With call-back style, it’s more OO, you are more likely operate on objects, and assign new feature to an object by just passing a function as parameter, which requires you not think programming as code line by line, you should think in objects and behaviors.</p>
<h2 id="Mongo-DB"><a href="#Mongo-DB" class="headerlink" title="Mongo DB"></a>Mongo DB</h2><p>Mongo got different titles, No-SQL, document DB, Object DB. I would prefer to consider it as a JSON db.<br>Database, as core backend for any application, can be a very big topic. I would rather leave it to DBAs, I’m a programmer, so I’m not going talk much about the DB part of it. What I would like to say is, just couple of days ago, I heard that there is a system has been running for more than 30 years, serving millions citizen of New Zealand. And the system was built one something called IMS, if you google it, you will find “The IMS Database component stores data using a hierarchical model.”. This hierarchical model, fundamentally, is the same model like JSON, although IMS might store things in binary, but JSON store it in string. This brings me the question that why javascript is prosperous these days, while IMS is sunsetting. If you compare IMS with modern technology, you probably will found IMS does better than modern ones in many aspects, in terms of stability, transactional, data integrity, performance. Then why there are less and less users? I think it could be caused by<br>1 IMS as an IBM product, it’s not open enough, that customer used to pay huge amount of money to service providers. It seems it was the way how technical companies make money.<br>2 Technically, the system might be powerful, but it might not friendly for both developer and user.  Does this mean usability could be the most important factor for whether a system can succeed or not?</p>
<h2 id="Dockerize"><a href="#Dockerize" class="headerlink" title="Dockerize"></a>Dockerize</h2><p>Docker is so popular, so let’s just go straight to code.</p>
<h3 id="Node-js-1"><a href="#Node-js-1" class="headerlink" title="Node.js"></a>Node.js</h3><p>Dockerfile<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FROM node:latest</span><br><span class="line">RUN mkdir -p /usr/src/app</span><br><span class="line">WORKDIR /usr/src/app</span><br><span class="line">COPY package.json /usr/src/app/</span><br><span class="line">COPY . /usr/src/app</span><br><span class="line">EXPOSE 3000</span><br><span class="line">CMD [ <span class="string">"npm"</span>, <span class="string">"start"</span> ]</span><br></pre></td></tr></table></figure></p>
<p>This docker file is pretty self intuitive, except the last line, it starts the nodejs process by reading information from the package.json. Which is the “script” section of the file.<br>I’m not including node js project code itself here, as the nodejs itself might require much more effort to learn. I will just focus on the deodorization of it here.<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">"name"</span>: <span class="string">"nodetest1-2017"</span>,</span><br><span class="line"> <span class="string">"version"</span>: <span class="string">"0.0.0"</span>,</span><br><span class="line"> <span class="string">"private"</span>: <span class="literal">true</span>,</span><br><span class="line"> <span class="string">"scripts"</span>: &#123;</span><br><span class="line">  <span class="string">"start"</span>: <span class="string">"node --inspect=0.0.0.0:9229 ./bin/www"</span></span><br><span class="line"> &#125;,</span><br><span class="line"> <span class="string">"dependencies"</span>: &#123;</span><br><span class="line">  <span class="string">"body-parser"</span>: <span class="string">"~1.18.2"</span>,</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></p>
<p>you will also need a docker-compose file, as your nodejs container will talk to mongo container.<br>docker-compose.yml, nodejs section only,<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">"2.1"</span></span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    container_name: app</span><br><span class="line">    build: .</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">"3000:3000"</span></span><br><span class="line">      - <span class="string">"9229:9229"</span></span><br></pre></td></tr></table></figure></p>
<p>you could now start your containerized application by<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up</span><br></pre></td></tr></table></figure></p>
<h3 id="Mongo"><a href="#Mongo" class="headerlink" title="Mongo"></a>Mongo</h3><p>the nodejs container was actually built by docker file that pull an official nodejs image and copy your files in to the container. for mongo let’s just pull the image. so we just need add a few lines to the docker compose file.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">"2.1"</span></span><br><span class="line">services:</span><br><span class="line">  app:</span><br><span class="line">    container_name: app</span><br><span class="line">    build: .</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">"3000:3000"</span></span><br><span class="line">      - <span class="string">"9229:9229"</span></span><br><span class="line">    links:</span><br><span class="line">      - mongo</span><br><span class="line">  mongo:</span><br><span class="line">    container_name: mongo</span><br><span class="line">    image: mongo</span><br><span class="line">    volumes:</span><br><span class="line">      - ./data:/data/db</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">"27017:27017"</span></span><br></pre></td></tr></table></figure></p>
<p>it just add new container based on mongo image, and expose the mongo ports, and share the local data folder with the /data/db directory inside the container. Now you start both container by<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up</span><br></pre></td></tr></table></figure></p>
<p>Unsurprisingly it does not work for you. It didn’t work for me as well. couple of things that I addressed to make it work finally.<br>1 Access issue to the local folder data from the container.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2018-10-11T22:54:43.593+0000 E STORAGE  [initandlisten] WiredTiger error (1) [1539298483:593264][1:0x7f8313773a00], connection: __posix_open_file, 715: /data/db/WiredTiger.wt: handle-open: open: Operation not permitted Raw: [1539298483:593264][1:0x7f8313773a00], connection: __posix_open_file, 715: /data/db/WiredTiger.wt: handle-open: open: Operation not permitted</span><br></pre></td></tr></table></figure></p>
<p>Because <a href="https://github.com/docker-library/mongo/issues/243" target="_blank" rel="noopener">I was using win10, while container is Linux</a>.  You would need to run docker with windows container, but the windows image is so big, and requires much more resources.  </p>
<p>My workaround is just remove the volumnes section from the docker composer file.  as I don‘t have the needs to share the data. Or I would say, in many scenarios, you don’t really need the  data been shared between host and container.  One major purpose of deodorization is for “infra as code”, so you could automate the whole build, deploy and test.  if the “infra” should be coded (dockerfile, docker-compose), if you have some data that required by your deodorized mongo container, it should also be “coded”. Basically you start everything from script, and after job done, there should be nothing left.  This should apply to most of case before production.</p>
<p>If you still want to share the data folder, here are some of the options</p>
<ul>
<li>run your linux container in linux host </li>
<li>run windows container if you run docker in windows.</li>
<li>create a non-ntfs partition on windows, and map folders from there.</li>
</ul>
<p>2 Now assuming your mongo instance runs fine now, but your nodejs process just can’t reach mongdb. you might not able to see following line after your container started.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mongo    | 2018-10-11T23:11:33.262+0000 I NETWORK  [listener] connection accepted from 172.19.0.3:43876 <span class="comment">#1 (1 connection now open)</span></span><br><span class="line">mongo    | 2018-10-11T23:11:33.278+0000 I NETWORK  [conn1] received client metadata from 172.19.0.3:43876 conn1: &#123; driver: &#123; name: <span class="string">"nodejs"</span>, version: <span class="string">"2.2.36"</span> &#125;, os: &#123; <span class="built_in">type</span>: <span class="string">"Linux"</span>, name: <span class="string">"linux"</span>, architecture: <span class="string">"x64"</span>, version: <span class="string">"4.9.93-linuxkit-aufs"</span> &#125;, platform: <span class="string">"Node.js v10.11.0, LE, mongodb-core: 2.1.20"</span> &#125;</span><br></pre></td></tr></table></figure></p>
<p>the reason is that your node.js container can’t reach the mongo container, as they are basically different machine. Your node.js code probably looks like following<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> mongo = <span class="built_in">require</span>(<span class="string">'mongodb'</span>);</span><br><span class="line"><span class="keyword">var</span> monk = <span class="built_in">require</span>(<span class="string">'monk'</span>);</span><br><span class="line"><span class="keyword">var</span> db = monk(<span class="string">'localhost:27017/nodetest1'</span>);</span><br></pre></td></tr></table></figure></p>
<p>Apparently, localhost won’t work, as the mongo is in another machine. what you could do are:<br>1 find out your mongo container ip, and use it there.<br>2 use your host ip(docker nat one), as you have exposed the port.<br>but both of these are not decent enough, as we have linked the node.js container to the mongo container in the compose file, you can just use “mongo”, the container name of mongo.<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> mongo = <span class="built_in">require</span>(<span class="string">'mongodb'</span>);</span><br><span class="line"><span class="keyword">var</span> monk = <span class="built_in">require</span>(<span class="string">'monk'</span>);</span><br><span class="line"><span class="keyword">var</span> db = monk(<span class="string">'mongo:27017/nodetest1'</span>);</span><br></pre></td></tr></table></figure></p>
<p>the only concern is that if you want your code run without a container, the code won’t work. But most of time these connection related values are parameterized or stored in configuration file. what you need do is to switch values between different environment, which could be a separate topic.</p>
<h2 id="Remaining-issues"><a href="#Remaining-issues" class="headerlink" title="Remaining issues."></a>Remaining issues.</h2><p>You might see that I have turned on debug of the node.js process, but I found it did not work if I run it in container.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/11/Dockerize-Mongo-and-Nodejs/" data-id="cjnh1d3k300039wvootys99o0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Principles" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/11/Principles/" class="article-date">
  <time datetime="2018-10-11T09:37:14.000Z" itemprop="datePublished">2018-10-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/11/Principles/">Principles</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Principles for the Voyage programme</p>
<p>As the idea of Voyage is to learn and practice a bunch of technics and write notes about it, it’s better to have some principles amount all the practice and articles, so they serve the same purpose under the programme.</p>
<p>I have come with a general purpose of the whole programme that it helps me to gain in-depth (enough) understanding of the technics. If possible it should also help anyone who reads the articles as well.</p>
<p>Some common challenges when you start learning at new technics are:</p>
<p>1 It might easy to understand the general idea of the new technics, but not in-depth enough for you to start using it in projects.</p>
<p>2 the best way to solve the point one is to practice, but it actually brings an even bigger challenge, to sort out the environment and make it work as told by many 15 minutes tutorials from the internet.</p>
<p>3 Many tutorials from the internet were based on a certain environment and certain version of tools, which makes the tutorial not workable after a couple of years.</p>
<p>4 Information got from the internet about new technics are small pieces, sometimes it will just a few lines of commands or code, without telling why. Which you don’t really learn from it, you barely solved an incident with a workaround, if you are lucky enough that found the piece you need.</p>
<p>….</p>
<p>N, You need to go fishing this weekend, and need prepare the tackle tonight.</p>
<p>N+1, Your 10-year-old machine just doesn’t work for the gigantic software.</p>
<p>There could be a hundred reason that you gave up or stopped before you really learnt the truth of a certain technic.</p>
<p>To help myself and potential readers to embrace the challenges, I came up with following principles for the programme.</p>
<p>Practice perspective:</p>
<p>1 Make the practice have least dependent on environment, by adopting any possible means like virtualizing, containerizing, scripting…</p>
<p>2 Address most core concept and component only, with reasonable enough depth.</p>
<p>3 Examples should be runnable within 30 minutes.</p>
<p>Article perspective:</p>
<p>1 Only cover one main component in each article.</p>
<p>2 Maximize the life of the content of the article.</p>
<p>3 Keep improving the English language, so the article is short but clear.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/11/Principles/" data-id="cjnh1d3k600049wvoj9wwwwro" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Voyage-Home" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Voyage/2018/10/11/Voyage-Home/" class="article-date">
  <time datetime="2018-10-11T08:29:29.000Z" itemprop="datePublished">2018-10-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Voyage/2018/10/11/Voyage-Home/">Voyage Home</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>I landed in New Zealand on November 26th 2017. Started my adventure in a country different from where I was born and lived for 36 years.</p>
<p>It was not a hard decision for me, personally, to come here. But it was a hard decision for my family.</p>
<p>I was an IT specialist in IBM, plus a manager in charge of a team about 25 members. It seems everything looks OK for me, an average guy with an average salary, got a below average apartment. But, due to my pessimistic view in life, I got a strong feeling of middle-age crisis. Been working in IBM for more than 7 years, failed some external interviews for potential jumps, I realized that the ultimate capability of survival need be examed in the open market. The team, position, resource and network in IBM are temporary. Due to the model that IBM GBS works, and the increasing labour cost in China, the business model won’t last forever, especially for the department I was working in. The capability of survival and be competitive need be examed globally. That’s why I started looking outside of IBM China since 2016. And by late 2017, I got the opportunity to work in New Zealand, while still under the IBM umbrella.</p>
<p>But the opportunity was just to work for a specific project, I need to return to China once the project finished. And initially, it was expected to be 8 months only. I could not move the whole family to New Zealand with the 8 months assignment, as my wife got her own career, or job that she won’t quit for my 8 months assignment. I could not bring my 6-year-old son on my own, It was obvious that I won’t be able to take care of him while working fulltime in a totally new environment. Which means if I want to go, I have to go alone, leaving my wife, a full-time doctor, to take care of the 6-year-old boy. It was a tough decision for the family, for my wife and my son, although I did not ask for his consent.</p>
<p>With all the support and trust of my wife, I decided and managed to take the step, a forward-only step. That’s why I’m sitting here writing my story of Voyage. the voyage is not for my journey of New Zealand, it’s for something else.</p>
<p>I left home Nov 25 2017, a lot of things happened, but most of them are not important for this story, until a couple of months before my assignment end.</p>
<p>It was a Sunday, after a couple of whisky with my Chinese landlord, who is a nice guy and could potentially be described in another story, We had a coffee around 7 PM and I went to bed, not for sleep. while browsing information from the internet, I found, in New Zealand, it’s possible to buy an old yacht, an 8–12 meter affordable one, and then you can sail around the world, even the yacht could be 30-40 years old. Especially when you work as a senior IT specialist in New Zealand, you could really settle the family with a few years, and then you should have the possibility (time and money) to sail around the world. Which would almost not possible to achieve in China, as an IT guy, an average one(yes, an average IT guy in China could be a senior one in New Zealand — don’t tell any Kiwi I said so). I came into numerous ideas about how to make it happen, although I forgot most of them already. The only thing I remembered about that night was, from 7 PM till 7 AM the next day, I did not sleep a single minute, the coffee could be one of the causes, but I think the major factor is the exiting idea of sailing around the world.</p>
<p>Knowing the possibility of sailing around the world is not just about buying a boat and learn to sail it. It gives me a purpose for my life. I always think about what’s the meaning of life, more specifically, my life. I could not get the answer, the only thing that I could understand was the meaning of life is the journey of life itself, which means to maximize the meaning of my life, is to maximize my experience of life, visit as many places as you can, try as many food as you can, meet as many people as you can. This belief of the meaning of life, do influence how I make my decisions. But it does not give my life a vision, which I realized, at age around 40, it’s essential for everyone, especially for people from China like me do not have religious beliefs.</p>
<p>Vision, sometimes known as a dream, is more than a dream, as long as it leads to actions in reality. And the reality for me is I only have a few months visa for staying in New Zealand, to be able to settle the family and then chase the dream, I need to have the capability to stay longer decently, which ultimately means I need get a job, long term one.</p>
<p>Back to the initial decision to come to New Zealand, It was already part of my plan to get the New Zealand PR if possible. There was a lot of debate about whether the family should pursuing moving to New Zealand permanently, while China might have a more promising future, financially at least. But getting a PR, if possible, was fully agreed in the family discussion. Having a vision of sailing around the world, which consistent with my understanding of the meaning of life, is the best thing I got from New Zealand, it also changed my plan from getting PR if possible to “get the PR”. And the only way for me to get the PR is to get a longer employment in New Zealand, inside or outside of IBM. I started trying some external positions a few months before the planned end date of my assignment, unfortunately, none of them worked out. Which did not really surprise me, although it did hurt my confidence a little bit, as I knew it’s not easy to get a job in the New Zealand market.</p>
<p>Having my confidence hurt by failed interviews, I realized that I need to refresh my knowledge and skill, so I can survive and be competitive in NZ IT market. The best way to gain knowledge would be applying it in daily work, but most of the time you got trapped by the knowledge you apply in daily work, rather than gain new ones. Thus after reading hundreds of job positions, I listed technics that required by the market and suit my background, and decided to start a POC programme to cover the listed technics as much as possible, as my learning practice. also could potentially become my stories for future interviews. And the name of the programme is — Voyage, for my dream of sailing around the world. The outcome of the Voyage will be a series of articles about the technics I learned, for the purpose of sharing and also to exam my understanding of the technic, as you must have sufficient understanding before you can write an article about it.</p>
<p>Now, it’s time to weigh the anchor!</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kennylnz.github.io/2018/10/11/Voyage-Home/" data-id="cjnh1d3kh00069wvo9uxfguzw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/Voyage/archives/2018/10/">October 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/Voyage/2018/10/20/Docker-Notes/">Docker Notes</a>
          </li>
        
          <li>
            <a href="/Voyage/2018/10/19/Docker-Summarize/">Docker Summarize</a>
          </li>
        
          <li>
            <a href="/Voyage/2018/10/14/Access-DynamoDB-from-Browser/">Access DynamoDB from Browser</a>
          </li>
        
          <li>
            <a href="/Voyage/2018/10/13/Dockerize-Spark-2-3-2-Hadoop-2-7-1/">Dockerize Spark 2.3.2 + Hadoop 2.7.1</a>
          </li>
        
          <li>
            <a href="/Voyage/2018/10/11/Dockerize-Mongo-and-Nodejs/">Dockerize Mongo and Nodejs</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Kenny Liu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/Voyage/" class="mobile-nav-link">Home</a>
  
    <a href="/Voyage/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/Voyage/fancybox/jquery.fancybox.css">
  <script src="/Voyage/fancybox/jquery.fancybox.pack.js"></script>


<script src="/Voyage/js/script.js"></script>



  </div>
</body>
</html>